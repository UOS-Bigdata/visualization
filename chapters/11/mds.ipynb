{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Dimensional Scaling \n",
    "<!-- 11-2 -->\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Idea of Multi Dimensional Scaling***\n",
    "\n",
    "두 원소 $x, y$가 있다고 합시다. 두 원소 $x,y$의 거리를 $d(x,y)$라고 합시다.\n",
    "\n",
    "$d(x,y)$를 함수로 보면 거리함수는 두 원소를 입력으로 받아서 실수값을 출력으로 합니다. 이를 좀 더 자세히 표현해볼까요?\n",
    "\n",
    "- $\\mathcal{X}$: 데이터의 입력공간\n",
    "- $d:\\mathcal{X} \\times \\mathcal{X} \\mapsto \\mathbb{R}$: 거리함수, 두 데이터를 받아서 실수 값을 출력으로 함.\n",
    "\n",
    "여기서 $d(\\cdot, \\cdot)$가 거리함수라면 어떤 함수도 거리함수가 될까요? 거리함수는 아래의 성질을 만족해야 합니다.\n",
    "\n",
    "- $d(x,y) \\geq 0$ \n",
    "- $d(x,x) = 0$ \n",
    "- $d(x,y) = d(y,x)$ (대칭성)\n",
    "- $d(x,z) \\leq d(x,y) + d(y,z)$  (삼각부등식)\n",
    "\n",
    "함수 $d$가 위 조건을 만족한다면 모두 거리함수가 됩니다. 그래서 거리는 종류가 매우 많습니다. \n",
    "\n",
    "우리는 고전적인 거리함수를 실생활에서 사용합니다. 바로 유클리디안 거리입니다. 우리가 사용할 유클리디안 거리는 다음과 같습니다.\n",
    "- $\\mathcal{X}$를 $\\mathbb{R}^d$로 놓습니다.\n",
    "- $x = (x_1, \\cdots, x_d), y= (y_1, \\cdots, y_d)$로 $\\mathbb{R}^d$의 원소로 놓습니다.\n",
    "- 유클리디안 거리\n",
    "$$d(x,y) = \\sqrt{\\sum_{j=1}^d (x_i - y_j)^2} $$\n",
    "\n",
    "이제 $d$차원 데이터 $n$개를 생각해봅시다. 각각의 데이터를 $x_1, \\cdots, x_n \\in \\mathbb{R}^d$라고 합시다. 여기서 $x_i$를 아래와 같이 표시합니다.\n",
    "- $x_i = (x_{i1}, \\cdots, x_{id})$\n",
    "\n",
    "여기서 두 데이터 $x_i$와 $x_j$에 대해서 거리를 $d_{ij}$라고 합시다. $d_{ij}^2$은 아래와 같이 쓸 수 있습니다.\n",
    "$$d_{ij}^2 = \\sum_{k=1}^d(x_{ik}-x_{jk})^2$$\n",
    "\n",
    "우리가 데이터들의 거리에만 관심이 있다면 데이터들의 중심에 무관하게 거리의 값이 계산됩니다. 예를 들어 모든 데이터의 중심을 $c=(c_1, \\cdots, c_d)$로 옮기더라고 새로운 데이터 $x_i+c$와 $x_j+c$의 거리는 동일합니다. 그래서 우리가 데이터들의 거리를 구할때는 평균이 0이 되도록 표준화를 하고 구해도 됩니다. (scaling을 하지 않습니다) 그래서 다음과 같이 가정을 해도 거리만들 생각하는데는 문제가 없겠지요.\n",
    "\n",
    "- 가정: $\\sum_{i=1}^n x_i = 0 \\in \\mathbb{R}^d$\n",
    "\n",
    "데이터들의 거리를 계산할 수 있으니 데이터들의 거리를 확인하기 위해서 시각화를 할 수 있을까요? 만약 고차원 자료라면 데이터간의 거리를 확인하기 위한 시각화 결과물을 그릴 수 없을 것입니다. 여기서 우리는 차원 축소를 생각합니다. \n",
    "$d$차원 데이터를 $q$차원 데이터로 축약하는 선형변환은 무엇일까요? \n",
    "\n",
    "$$A:\\mathbb{R}^d \\mapsto \\mathbb{R}^q$$\n",
    "\n",
    "$q\\times d$ 행렬입니다. 데이터 $x$를 $q$차원으로 축약한 데이터는 \n",
    "$$\\hat x = Ax$$\n",
    "가 되겠지요? 그러면 어떤 차원축소 방법 다시 말해 어떤 $A$를 선택해야 할까요? 우리는 애초에 데이터간의 거리를 확인하기 위해서 차원 축소를 하였습니다. 따라서 원래 축약되기 이전에서의 데이터의 거리가 축약된 이후에도 잘 보존되기를 원할 것입니다. 즉 고차원에서 가까운 두 데이터가 저차원 공간에서 여전히 가깝기를 원하겠지요. 우리의 이런 바램을 식으로 표현하면 어떻게 될까요?\n",
    "\n",
    "먼저 축약된 두 데이터 $\\hat x_i:= Ax_i$, $\\hat x_j:= Ax_j$ 를 생각하고 유클리디안 거리를 생각해봅시다.\n",
    "\n",
    "$$\\hat d_{ij} = \\sqrt{\\sum_{k=1}^q (\\hat x_{ik}- \\hat x_{jk})^2}$$\n",
    "\n",
    "그러면 우리는 $\\hat d_{ij} \\simeq \\hat d_{ij}$ 가 되도록 $\\hat d_{ij}$를 만들어야 할 것입니다. 즉, 차원축소 함수인 $A$를 잘 선택해서 $\\hat d_{ij} \\simeq \\hat d_{ij}$이 되도록 만들어야 할 것입니다. 이를 위해 다음 목적함수를 정의하고 아래 식을 최소화 하는  $A$를 찾으면 될 것입니다. \n",
    "\n",
    "$$\\sum_{i,j}\\| \\hat d_{ij} - d_{ij}\\|^2 $$\n",
    "\n",
    "이렇게 $A$를 구하는 방법을 metric Multi Dimensional Scaling (mMDS)라 부릅니다. 여기서 원래 공간에서 distance와 축약된 공간에서 distance의 차이를 제곱거리($l_2$-distance)를 사용하여 목적함수를 정의했지만, 다른 함수를 사용할 수도 있습니다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09d430ac884b7b963decef9a3390e18440a81a639eb9d9528489333ac105a61d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
